{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\",parse_dates=[\"Date\"])\n",
    "test = pd.read_csv(\"test.csv\",parse_dates=[\"Date\"])\n",
    "store = pd.read_csv(\"store.csv\")\n",
    "sample = pd.read_csv(\"sample_submission.csv\")\n",
    "sample = sample.drop([\"Sales\"],axis=1)\n",
    "\n",
    "print(\"If no data, store is open as most of the days it's open\")\n",
    "train =train.fillna(1)\n",
    "test=test.fillna(1)\n",
    "\n",
    "print(\"Consider only open stores for training. Closed stores wont count into the score\")\n",
    "train = train[train[\"Open\"] != 0]\n",
    "print(\"Use only Sales bigger then zero\")\n",
    "train = train[train[\"Sales\"] > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train,store,on=\"Store\")\n",
    "test = pd.merge(test,store,on=\"Store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Nulls in train data: \\n\")\n",
    "print(train.isna().sum())\n",
    "print(\"\\n Nulls in test data: \\n\")\n",
    "print(test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engg(data):\n",
    "    mappings = {'0':\"0\", 'a':\"1\", 'b':\"2\", 'c':\"3\", 'd':\"4\"}\n",
    "    mappings1 = {'0':\"0\", 'Jan,Apr,Jul,Oct':\"1\", 'Feb,May,Aug,Nov':\"2\", 'Mar,Jun,Sept,Dec':\"3\"}\n",
    "    data[\"StoreType\"].replace(mappings, inplace=True)\n",
    "    data[\"PromoInterval\"].replace(mappings1, inplace=True)\n",
    "    data.Assortment.replace(mappings, inplace=True)\n",
    "    data.StateHoliday.replace(mappings, inplace=True)\n",
    "    \n",
    "    data['Year'] = data.Date.dt.year\n",
    "    data['Month'] = data.Date.dt.month\n",
    "    data['Day'] = data.Date.dt.day\n",
    "    data['WeekOfYear'] = data.Date.dt.weekofyear\n",
    "    data['Day_Week'] = data.Date.dt.weekday_name\n",
    "    mappings2 = {'Sunday':\"0\", 'Monday':\"1\", 'Tuesday':\"2\", 'Wednesday':\"3\", 'Thursday':\"4\", 'Friday':\"5\", 'Saturday':\"6\"}\n",
    "    data[\"Day_Week\"].replace(mappings2, inplace=True)\n",
    "    data['CompetitionOpen'] = 12 * (data.Year - data.CompetitionOpenSinceYear) + \\\n",
    "        (data.Month - data.CompetitionOpenSinceMonth)\n",
    "    data['CompetitionOpen'] = data.CompetitionOpen.apply(lambda x: x if x > 0 else 0)\n",
    "    data['PrvsHoliday'] = np.where((data[\"StateHoliday\"].shift(1)==1) | (data[\"SchoolHoliday\"].shift(1)==1),1,0)\n",
    "    data['NxtHoliday'] = np.where((data[\"StateHoliday\"].shift(-1)==1) | (data[\"SchoolHoliday\"].shift(-1)==1),1,0)\n",
    "    data['PromoOpen'] = 12 * (data.Year - data.Promo2SinceYear) + \\\n",
    "        (data.WeekOfYear - data.Promo2SinceWeek) / 4.0\n",
    "    data['PromoOpen'] = data[\"PromoOpen\"].apply(lambda x: x if x > 0 else 0)\n",
    "    data.loc[data.Promo2SinceYear == 0, 'PromoOpen'] = 0\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = feature_engg(train)\n",
    "test = feature_engg(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train[\"CompetitionDistance\"].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"CompetitionDistance\"].fillna(np.median(train[\"CompetitionDistance\"].dropna()),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train[\"CompetitionOpenSinceMonth\"].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =train.fillna(0)\n",
    "test =test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def type_conv(df):\n",
    "#    df['Store'] = df['Store'].astype('category')\n",
    "#    df['DayOfWeek'] = df['Store'].astype('category')\n",
    "#    df['StateHoliday'] = df['StateHoliday'].astype('category')\n",
    "#    df['SchoolHoliday'] = df['SchoolHoliday'].astype('category')\n",
    "#    df['Assortment'] = df['Assortment'].astype('category')\n",
    "#    df['StoreType'] = df['StoreType'].astype('category')\n",
    "#    df['Promo2']= df['Promo2'].astype('category')\n",
    "#    df['PromoInterval']= df['Promo2'].astype('category')\n",
    "#    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = type_conv(train)\n",
    "#test = type_conv(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop([\"CompetitionOpenSinceMonth\",\"CompetitionOpenSinceYear\",\"Customers\",\"Promo2SinceWeek\",\"Promo2SinceYear\"],axis=1)\n",
    "test = test.drop([\"CompetitionOpenSinceMonth\",\"CompetitionOpenSinceYear\",\"Promo2SinceWeek\",\"Promo2SinceYear\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(train[[\"StoreType\",\"Assortment\",\n",
    "                          \"PromoInterval\"]],prefix_sep=\"_\",drop_first=True)\n",
    "df1 = pd.get_dummies(test[[\"StoreType\",\"Assortment\",\n",
    "                          \"PromoInterval\"]],prefix_sep=\"_\",drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train,df],axis=1)\n",
    "test = pd.concat([test,df1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe(y, yhat):\n",
    "    return np.sqrt(np.mean(((y - yhat)/y) ** 2))\n",
    "\n",
    "def rmspe_xg(yhat, y):\n",
    "    y = np.expm1(y.get_label())\n",
    "    yhat = np.expm1(yhat)\n",
    "    return \"rmspe\", rmspe(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop([\"Sales\",\"Date\",\"Open\",],axis=1)\n",
    "y_train = train[\"Sales\"]\n",
    "X_test = test.drop([\"Id\",\"Date\",\"Open\",],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=15)\n",
    "X_train_scale = scaler.fit_transform(X_train)\n",
    "X_val_scale = scaler.transform(X_val)\n",
    "X_test_scale = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_cv = KFold(n_splits=4, shuffle=True, random_state=0)\n",
    "outer_cv = KFold(n_splits=4, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "params = {\"objective\": \"reg:linear\",\n",
    "          \"booster\" : \"gbtree\",\n",
    "          \"eta\": 0.1,\n",
    "          \"max_depth\": 10,\n",
    "          \"subsample\": 0.85,\n",
    "          \"colsample_bytree\": 0.4,\n",
    "          \"min_child_weight\": 6,\n",
    "          \"silent\": 1,\n",
    "          \"thread\": 1,\n",
    "          \"seed\": 1301\n",
    "          }\n",
    "num_boost_round = 2000\n",
    "\n",
    "\n",
    "y_train = np.log(y_train)\n",
    "y_val1 = np.log(y_val)\n",
    "dtrain = xgb.DMatrix(X_train_scale, y_train)\n",
    "dvalid = xgb.DMatrix(X_val_scale, y_val1)\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=10, \\\n",
    "  feval=rmspe_xg, verbose_eval=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validating\")\n",
    "yhat1 = gbm.predict(xgb.DMatrix(X_val_scale))\n",
    "error = rmspe(y_val, np.exp(yhat1))\n",
    "print('RMSPE: {:.6f}'.format(error))\n",
    "\n",
    "print(\"Make predictions on the test set\")\n",
    "dtest = xgb.DMatrix(X_test_scale)\n",
    "test_probs = gbm.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr=RandomForestRegressor(n_estimators=50)\n",
    "rfr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validating\")\n",
    "yhat = rfr.predict(X_val)\n",
    "error = rmspe(y_val, np.exp(yhat))\n",
    "print('RMSPE: {:.6f}'.format(error))\n",
    "\n",
    "print(\"Make predictions on the test set\")\n",
    "test_probs_rfr = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmspe(y_val, np.exp(yhat2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvr = LinearSVR(C=.01).fit(X_train_scale,y_train)\n",
    "model = SelectFromModel(lsvr, prefit=True)\n",
    "X_train_scale_sm = model.transform(X_train_scale)\n",
    "print(X_train_scale_sm.shape)\n",
    "X_test_scale_sm = model.transform(X_test_scale)\n",
    "print(X_train_scale.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR, LinearSVR\n",
    "svr = LinearSVR(C=0.01)\n",
    "svr.fit(X_train_scale_sm,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scale_sm = model.transform(X_val_scale)\n",
    "print(\"Validating\")\n",
    "yhat = svr.predict(X_val_scale_sm)\n",
    "error = rmspe(y_val, np.exp(yhat))\n",
    "print('RMSPE: {:.6f}'.format(error))\n",
    "\n",
    "print(\"Make predictions on the test set\")\n",
    "test_probs_svr = svr.predict(X_test_scale_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = LinearRegression()\n",
    "X_val_scale_sm = model.transform(X_val_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.fit(X_train_scale_sm,y_train)\n",
    "print(\"Validating Linear Regression\")\n",
    "yhat_lr = regr.predict(X_val_scale_sm)\n",
    "error = rmspe(y_val, np.exp(yhat_lr))\n",
    "print('RMSPE: {:.6f}'.format(error))\n",
    "\n",
    "print(\"Make predictions on the test set\")\n",
    "test_probs_lr = regr.predict(X_test_scale_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso,Ridge\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "my_scorer = make_scorer(rmspe, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_grid = {'alpha': [1e-3,1e-2,1e-1]}\n",
    "lasso = Lasso()\n",
    "# Non_nested parameter search and scoring\n",
    "gs = GridSearchCV(estimator=lasso, param_grid=p_grid,\n",
    " cv=inner_cv, scoring=my_scorer, return_train_score=True)\n",
    "gs.fit(X_train_scale_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validating Lasso\")\n",
    "yhat_lr = gs.predict(X_val_scale_sm)\n",
    "error = rmspe(y_val, np.exp(yhat_lr))\n",
    "print('RMSPE: {:.6f}'.format(error))\n",
    "print('Best params are: {0}'.format(gs.best_params_))\n",
    "\n",
    "print(\"Make predictions on the test set\")\n",
    "test_probs_lr = regr.predict(X_test_scale_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_grid = {'alpha': [1e-3,1e-2,1e-1]}\n",
    "ridge = Ridge()\n",
    "# Non_nested parameter search and scoring\n",
    "gs = GridSearchCV(estimator=ridge, param_grid=p_grid,\n",
    " cv=inner_cv, scoring=my_scorer,return_train_score=True)\n",
    "gs.fit(X_train_scale_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validating Ridge\")\n",
    "yhat_lr = gs.predict(X_val_scale_sm)\n",
    "error = rmspe(y_val, np.exp(yhat_lr))\n",
    "print('RMSPE: {:.6f}'.format(error))\n",
    "print('Best params are: {0}'.format(gs.best_params_))\n",
    "print(\"Make predictions on the test set\")\n",
    "test_probs_lr = regr.predict(X_test_scale_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Submission\n",
    "result = pd.DataFrame({\"Id\": test[\"Id\"], 'Sales': np.exp(test_probs), \"open\":test['Open']})\n",
    "#result[\"Sales\"]=np.where(result[\"open\"]==0,0,result[\"Sales\"])\n",
    "result=result.drop(\"open\",axis=1)\n",
    "result.to_csv(\"submission1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from livelossplot import PlotLossesKeras\n",
    "import tensorflow as tf\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "import keras.backend as K\n",
    "from keras.layers import LSTM,GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSPE_for_Keras(y, yhat):\n",
    "    return K.sqrt(K.mean(((y - yhat)/y) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.InteractiveSession()\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=np.shape(X_train_scale)[1],activation='relu',kernel_initializer = 'uniform'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(25,activation='relu',kernel_initializer = 'uniform'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation='relu',kernel_initializer = 'uniform'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='mean_absolute_percentage_error', optimizer='adam')\n",
    "model.fit(X_train_scale, y_train, epochs=20,batch_size=200, verbose=1,callbacks=[PlotLossesKeras()],validation_data=(\n",
    "    X_val_scale, y_val1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validating\")\n",
    "yhat_mlp = model.predict(X_val_scale)\n",
    "yhat_mlp = [x[0] for x in yhat_mlp]\n",
    "error = rmspe(y_val, np.exp(yhat_mlp))\n",
    "print('RMSPE: {:.6f}'.format(error))\n",
    "\n",
    "print(\"Make predictions on the test set\")\n",
    "test_probs_mlp = model.predict(X_test_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scale_rs = np.reshape(X_train_scale, (X_train_scale.shape[0],X_train_scale.shape[1],1))\n",
    "X_val_scale_rs = np.reshape(X_val_scale, (X_val_scale.shape[0],X_val_scale.shape[1],1))\n",
    "X_test_scale_rs = np.reshape(X_test_scale, (X_test_scale.shape[0],X_test_scale.shape[1],1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
